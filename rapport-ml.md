
nom : berradi meriem 
appogÃ©e:22007719

![image](https://github.com/user-attachments/assets/5616a879-06b7-4f83-ba71-84475fc8ac15)


# ğŸ“˜ **RAPPORT DESCRIPTIF â€“ PROJET DATA SCIENCE**

## *Dataset : Wine Recognition (Classification Multiclasses)*

---

## **1. Contexte & Objectif du Projet**

Le dataset **Wine Recognition** est un classique de la Data Science.
Il permet de classifier trois types de vins (classes 0, 1 et 2) Ã  partir de 13 caractÃ©ristiques chimiques telles que lâ€™alcool, le magnÃ©sium, lâ€™aciditÃ©, les polyphÃ©nols ou encore la couleur.

### ğŸ¯ **Objectif principal**

Construire une chaÃ®ne complÃ¨te de Machine Learning permettant de :

1. Charger et inspecter le dataset
2. Simuler un cas rÃ©el en introduisant des donnÃ©es manquantes
3. Nettoyer les donnÃ©es
4. RÃ©aliser une analyse exploratoire
5. Construire un modÃ¨le de classification
6. Ã‰valuer sa performance

---

## **2. Les DonnÃ©es (X et y)**

### ğŸ”¹ Variables explicatives (X)

13 caractÃ©ristiques chimiques des vins, parmi lesquelles :

* Alcohol
* Malic acid
* Ash
* Hue
* Proline (la caractÃ©ristique la plus discriminante)

### ğŸ”¹ Variable cible (y)

Trois classes :

* **0 : Classe 0**
* **1 : Classe 1**
* **2 : Classe 2**

â¡ï¸ Le dataset original contient **178 lignes** et **14 colonnes (13 features + 1 target)**.

---

## **3. Simulation de DonnÃ©es Manquantes (RÃ©alisme du Projet)**

Pour simuler un cas rÃ©el â€“ oÃ¹ les mesures chimiques peuvent manquer â€“ tu as introduit :

* **7% de valeurs manquantes dans toutes les colonnes (sauf target)**

Total NaN gÃ©nÃ©rÃ©s :
ğŸ‘‰ **~162 valeurs manquantes**

Ce processus reproduit un scÃ©nario industriel oÃ¹ les donnÃ©es sont imparfaites.

---

## **4. Nettoyage & Imputation**

### ğŸ”§ StratÃ©gie utilisÃ©e :

`SimpleImputer(strategy='mean')`

Pour chaque feature :

* `fit()` calcule la moyenne
* `transform()` remplace les NaN par cette moyenne

ğŸ”¹ RÃ©sultat :
**0 valeur manquante restante** aprÃ¨s imputation.

ğŸ“Œ *Note mÃ©thodologique*
Dans un projet strictement professionnel, on ferait lâ€™imputation **aprÃ¨s** le train/test split pour Ã©viter le **data leakage**.

---

## **5. Analyse Exploratoire (EDA)**

### ğŸ“Š Statistiques descriptives

Les premiÃ¨res colonnes montrent des amplitudes diffÃ©rentes :

* Variables comme **alcohol** â†’ bien rÃ©parties
* Variables comme **color_intensity** â†’ asymÃ©triques
* **Proline** â†’ trÃ¨s dispersÃ©e (Ã©cart-type Ã©levÃ©), bonne variable discriminante

### ğŸ“‰ Distribution de lâ€™alcool par classe

Le graphique montre une sÃ©paration claire :

* Classe 0 â†’ vins plus alcoolisÃ©s
* Classe 2 â†’ valeurs plus faibles
* Classe 1 â†’ intermÃ©diaire

Cela indique que **lâ€™alcool est un bon prÃ©dicteur**.

### ğŸ”¥ Matrice de corrÃ©lation

On observe des relations fortes :

* **Proline**, **alcalinity_of_ash**, **OD280** ont des corrÃ©lations marquÃ©es avec la classe.
* Certaines variables sont redondantes (corrÃ©lation > 0.7)

---

## **6. MÃ©thodologie de Split (Train/Test)**

`train_test_split(test_size=0.2, random_state=42)`

* Train : **142 lignes**
* Test : **36 lignes**

Pourquoi 20% ?
â†’ Suffisant pour valider un modÃ¨le tout en conservant un volume dâ€™entraÃ®nement solide.

Pourquoi random_state=42 ?
â†’ ReproductibilitÃ© des expÃ©riences.

---

## **7. ModÃ©lisation : Random Forest**

### Pourquoi un Random Forest ?

* Robuste aux donnÃ©es bruitÃ©es
* Supporte bien les corrÃ©lations entre variables
* Peu sensible aux valeurs extrÃªmes
* Capable de capturer des interactions complexes

### ParamÃ¨tres principaux :

* `n_estimators=150`
* `random_state=42`

Le modÃ¨le apprend Ã  distinguer les 3 classes de vin grÃ¢ce aux patterns extraits.

---

## **8. Ã‰valuation du ModÃ¨le**

### ğŸ¯ **Accuracy obtenue : environ 97â€“100 %**

TrÃ¨s fort score grÃ¢ce :

* Ã€ la simplicitÃ© du dataset
* Ã€ un fort pouvoir discriminant des features chimiques
* Ã€ la stabilitÃ© du Random Forest

### ğŸ“Œ Rapport de classification :

Les mÃ©triques (precision, recall, f1-score) sont **excellentes pour les 3 classes**.

### ğŸ§© Matrice de confusion

Peu ou pas dâ€™erreurs de classification :

* Les classes sont clairement sÃ©parables
* Le modÃ¨le capture trÃ¨s bien leurs signatures chimiques

---

## **9. Conclusion GÃ©nÃ©rale**

Ce projet illustre parfaitement toutes les Ã©tapes dâ€™un pipeline complet de Data Science :

1. Chargement des donnÃ©es
2. Simulation de donnÃ©es manquantes
3. Nettoyage (imputation)
4. EDA visuelle et statistique
5. Split mÃ©thodologique
6. ModÃ©lisation Random Forest
7. Ã‰valuation pertinente

ğŸ“ **CompÃ©tences validÃ©es :**

* Data wrangling
* Analyse exploratoire
* Nettoyage des valeurs manquantes
* Construction dâ€™un modÃ¨le supervisÃ©
* Lecture de mÃ©triques ML
* InterprÃ©tation de graphes

Le dataset WINE est un excellent terrain dâ€™apprentissage pour comprendre la classification multiclasses et lâ€™impact des variables chimiques sur la typologie des vins.

---
